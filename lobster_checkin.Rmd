---
title: "Trying to Reproduce Benestan et al. Assignment Results"
author: "Eric C. Anderson and Kelly Barr"
date: "October 8, 2015"
output: html_document
---


Here check some results that Louis Bernatchez's group had
on Lobster population genetics in this paper: 
[RAD genotyping reveals fine-scale genetic structuring and provides powerful population assignment in a widely distributed marine species, the American lobster (Homarus americanus)](http://onlinelibrary.wiley.com/doi/10.1111/mec.13245/abstract).

We found it strange that Benestan et al found that their power for assignment _decreased_ dramatically as they added
more markers past 3000.  This seems worrisome to us because it is a pattern characteristic of
high grading bias.  Here we use Eric's program `gsi_sim` to implement the Training-Holdout-Leave-one-out
(THL) procedure from 
[Anderson 2010](http://onlinelibrary.wiley.com/doi/10.1111/j.1755-0998.2010.02846.x/full) 
to assess power for assignment of lobsters to their sampling
locations of origin.  And we don't find as much power for that as Benestan and
colleagues reported.  We conclude they suffered some high-grading bias in the procedure they used, even
though they intended to eliminate any such bias.

Note that if you want to reproduce these results you will want to be on a Mac or a Unix system.
You will need to have `vcftools` installed and in your `$PATH` variable which is given in a
`~/.bashrc` file.  Likewise you will need `gsi_sim`
([https://github.com/eriqande/gsi_sim](https://github.com/eriqande/gsi_sim) commit 280734b4 or later)
compiled and on your `$PATH`.

To reproduce this work, clone this repo, install `gsi_sim` and `vcftools` and put them on your 
`$PATH` as listed in your `~/.bashrc`, then you have to download the file `10156-586.recode.vcf` from the
[Benestan et al. paper's Dryad site](http://datadryad.org/resource/doi:10.5061/dryad.q771r) and put it into
`./data/10156-586.recode.vcf` in the repository, and then open the [Rstudio](https://www.rstudio.com/)
project and knit the file `lobster_checkin.Rmd` to HTML within Rstudio.


## Setup
You gotta have the following libraries:
```{r, message=FALSE}
library(tidyr)
library(dplyr)
library(ggplot2)
library(stringr)
```

### Dealing with the individual IDs

First thing we need to do is correct some errors in the data set.  There are sampling locations codes in the
data set on Dryad that do not appear in the paper, and there are location codes in the paper that do not
appear in the data set!  A coauthor of the paper indicated that this could all be fixed by:

- Sampling sites EDN and CAP get renamed to MAG
- Sampling site SID gets renamed to DIN.

So, we are going to just do that and write out a corrected VCF file.  We put all the vcf output into a
directory called `intermediates`.
```{r}
dir.create("intermediates", showWarnings = FALSE)

# get the VCF file headers (indiv IDs, etc)
vcf_lines <- readLines("data/10156-586.recode.vcf")
header_idx <- which(str_detect(vcf_lines, "^#CHROM"))  # line has all the names
header_elements <- vcf_lines[header_idx] %>%
  str_split(., "\t") %>%
  "[["(.,1)

# now, rename the individuals as appropriate
ids <- header_elements[-(1:9)] %>%
  str_replace_all("EDN_", "MAG_a") %>%  # Note we append the a and b on the ID to keep them unique
  str_replace_all("CAP_", "MAG_b") %>%
  str_replace_all("SID_", "DIN_")

# and put that new header back into there and print it out
vcf_lines[header_idx] <- paste(c(header_elements[1:9], ids), collapse = "\t")

cat(vcf_lines, file = "intermediates/10156-586-IDs-corrected.vcf", sep = "\n")

# then get a list of the individuals that are in there:
system("source ~/.bashrc; vcftools --vcf intermediates/10156-586-IDs-corrected.vcf --out intermediates/get-indivs --depth")

Inds <- read.table("intermediates/get-indivs.idepth", stringsAsFactors = FALSE, header = TRUE) %>%
  tbl_df %>%
  mutate(SampSite = str_sub(INDV, 1, 3))
```
Here is what `Inds` looks like:
```{r}
Inds
```
We don't need the mean read depths.  That was just a convenient way to list all the individuals in
the file.

Now, we are actually going to need some text files that list which individuals are in different
populations.  We can do that like so:
```{r}
for(SS in unique(Inds$SampSite)) {
  Inds %>% 
    filter(SampSite == SS) %>%
    select(INDV) %>% 
    write.table(., file = file.path("intermediates", SS), row.names = FALSE, col.names = FALSE, quote = FALSE)
}
```


## Computing some Fst's
We are just going to compute Fst using VCF tools.  With multiple populations it computes
the "global" (not the
pairwise) Fst, which might not be what Benestan et al. did. 
It isn't entirely clear what Benestan et al. did, as they have only submitted data to 
Dryad and have not included any computer code documenting the analysis.  They said they
computed pairwise Fst using `hierfstat` but then you have $\frac{N(N-1)}{2}$ multiple values for each
locus (where N is the number of sampling location) so the
ranking method they would have used isn't immediately clear.  At any rate, using global
Fst should reasonably let you rank markers by how informative they are for some population
comparisons, since it will be correlated with pairwise Fst.  
```{r}
# first  make all the --weir-fst-pop commands
fst_comms <- paste("--weir-fst-pop", file.path("intermediates", unique(Inds$SampSite)), collapse = " ")

# then compute the Fst for all the markers
CALL <- paste("source ~/.bashrc; vcftools --vcf intermediates/10156-586-IDs-corrected.vcf --out intermediates/fst-all", fst_comms)
system(CALL)


# Now, read those in
FST <- read.table("intermediates/fst-all.weir.fst", header = TRUE, stringsAsFactors = FALSE) %>%
  tbl_df
```

Here is what they look like:
```{r}
FST
```

So, let's plot that and note that there are most definitely some loci that are big outliers.
```{r fstplot, fig.width=10, fig.height=7}
ggplot(FST, aes(x = WEIR_AND_COCKERHAM_FST)) + geom_histogram(binwidth = 0.001)
```


## Some functions to do THL (Training-Holdout-Leave-one-out)
We will write a few functions to do some things we need:
```{r}
# a function to turn a VCF file into a gsi_sim file.
# it will just take the name of the VCF input file and the output file
vcf2gsi_sim <- function(VCF, outf = "gs_baseline.txt") {
  # first output to a matrix of -1, 0, 1, and 2
  CALL <- paste("source ~/.bashrc; vcftools --vcf", VCF, "--out intermediates/tmp-one-two --012")
  system(CALL)
  
  # get the indivs
  gsIndivs <- scan("intermediates/tmp-one-two.012.indv", what = "character")
  N <- length(gsIndivs)
  
  # get the markers
  tmp <- scan("intermediates/tmp-one-two.012.pos", what = "character")
  # get their markers names by putting the Chromosome (always "un") and the
  # marker numbers together prepended with an X, so each will look like "X_un_3146850"
  gsMarkers <- paste("X", tmp[c(T,F)], tmp[c(F,T)], sep = "_")
  M <- length(gsMarkers)
  
  # now make a hashie thing to change some allele names and make it all two-columny
  alles <- c("1 1", "1 2", "2 2", "-1 -1")
  names(alles) <- c("0", "1", "2", "-1")
  
  # then read them in and make a matrix of "two-column genotypes
  genos <- alles[scan("intermediates/tmp-one-two.012", what = "character")] %>% 
    matrix(., nrow = N, byrow = TRUE)  
  
  rownames(genos) <- gsIndivs
  genos <- genos[,-1]  # note that we tear off the column that gives the index of each individual
  
  # now we need to sort the rows so that populations are together in case they arent already grouped
  # together.  Just a simple order on the rownames.
  genos <- genos[order(rownames(genos)),]
  
  
  # once we have done that we should modify the row names so that the first individual of each 
  # population has "POP NameOfPop\n" in its name, so we can print those out as they need to be
  # for gsi_sim.  Note that this is specific to the naming format on the lobster data
  pops <- str_sub(rownames(genos), 1, 3)
  firsties <- c(1, 1 + which(diff(as.numeric(factor(pops))) != 0))
  rownames(genos)[firsties] <- paste("POP ", pops[firsties], "\n", rownames(genos)[firsties], sep = "")
  
  
  # then we just spooge out the preamble and the genotypes.
  cat(nrow(genos), " ", ncol(genos), "\n", sep = "", file = outf)
  cat(gsMarkers, sep = "\n", file = outf, append = TRUE)
  write.table(genos, col.names = FALSE, quote = FALSE, sep = "    ", file = outf, append = TRUE)
  
  # return the name of the file written to:
  return(outf)
}

# from gsi_sim --self-assign output, slurp out the population each individual
# got assigned to, and note whether it is correct or not.
# this relies on having pop names that are exactly three letters long.
slurp_ass <- function(infile = "gs_out.txt") {
  tmp <- readLines(infile)
  tmp2 <- tmp[str_detect(tmp, "^SELF_ASSIGN_A_LA_GC_CSV")] %>%
    str_replace_all(., "^SELF_ASSIGN_A_LA_GC_CSV:/", "")
  str_split(tmp2, ";") %>% 
    sapply(., "[", 1:3) %>% 
    t %>%
    as.data.frame(stringsAsFactors = FALSE) %>%
    tbl_df %>%
    setNames(c("ID", "To", "Score")) %>%
    mutate(From = str_sub(ID, 1, 3))
}
```

## Split the data into Training and Test sets
We will just take (as close as possible) half of the individuals, randomly selected, to be
Training data, and the other half to be our Test (holdout) individuals.  We will identify who
they are and store that info in the variable `Split`
```{r}
set.seed(345) # for reproducibility
# permute them within sample location and then let every other one be a Training individual 
Split <- Inds %>%
  group_by(SampSite) %>%
  mutate(Pool = ifelse(sample(1:length(INDV)) %% 2 == 0, "Test", "Train")) %>%
  ungroup
```
Here is what `Split` looks like:
```{r}
Split
```

Then we make two new VCF files:
one of the Training individuals and one of the Test individuals.
```{r}
# first we make files with the names of the individuals
Split %>% 
  filter(Pool == "Test") %>% 
  select(INDV) %>% 
  unlist %>% 
  unname  %>%
  cat(., file = "intermediates/test-guys.txt", sep = "\n")

Split %>% 
  filter(Pool == "Train") %>% 
  select(INDV) %>% 
  unlist %>% 
  unname  %>%
  cat(., file = "intermediates/train-guys.txt", sep = "\n")

# then we run vcftools to grab those out:
system("source ~/.bashrc; vcftools --vcf intermediates/10156-586-IDs-corrected.vcf --keep intermediates/train-guys.txt --out intermediates/train --recode")
system("source ~/.bashrc; vcftools --vcf intermediates/10156-586-IDs-corrected.vcf --keep intermediates/test-guys.txt --out intermediates/test --recode")
```


## Compute FST via vcftools using just the Training data


Compute Fst's from the training set with vcftools.  The results are written to a file which
we then read into `train_FST` which has things sorted in descending order of FST:
```{r}
fst_comms <- paste("--weir-fst-pop", file.path("intermediates", unique(Inds$SampSite)), collapse = " ")
CALL <- paste("source ~/.bashrc; vcftools --vcf intermediates/train.recode.vcf --out intermediates/train-recode", fst_comms)
system(CALL)


# get a table of marker positions sorted by Fst high to low
train_FST <- read.table("intermediates/train-recode.weir.fst", header = TRUE, stringsAsFactors = FALSE) %>%
  tbl_df %>%
  arrange(desc(WEIR_AND_COCKERHAM_FST))
```
Here is what `train_FST` looks like:
```{r}
train_FST
```

## A function to do the THL method on a given number, nL, of loci

We are now almost there, but it will be convenient to have a function to which you can pass:

1. The number of loci to select
1. A data frame `Split` that tells us who is Training and who is Test
1. A data frame like train_FST
1. A VCF file with all the individuals and all the SNPs

And it will return to you a data frame telling you whether each individual was correctly assigned to
its sampling location or not (and also whether or not it was a Training or a Test individual.
For this to work, the ID's of the individuals all have to start with
a three-letter location code.
```{r}
thl <- function(nL, Split, train_FST, vcffile = "intermediates/10156-586-IDs-corrected.vcf") {
  # now, choose the first nL loci, write them to a file, and get all the individuals'
  # genotypes at those loci
  fn <- file.path("intermediates", "tmp_top_loci")
  train_FST[1:nL, ] %>%
    select(CHROM, POS) %>%
    write.table(., row.names = FALSE, col.names = FALSE, sep = "\t",
                quote = FALSE, file = fn)
  
  
  CALL <- paste("source ~/.bashrc; vcftools --vcf",
                vcffile,
                "--positions",
                fn, 
                "--recode --out",
                fn
  )
  
  system(CALL)
  
  
  # make a gsi_sim file of that:
  vcf2gsi_sim(paste(fn, "recode.vcf", sep = "."), 
              outf = paste(fn, "gsi_sim_input", sep = "."))
  
  # then run gsi_sim on it
  system(paste("source ~/.bashrc; /Users/eriq/Documents/git-repos/gsi_sim/gsisim -b", paste(fn, "gsi_sim_input", sep = "."),
               "--self-assign > intermediates/bigdump"))
  
  
  # and slurp out the assignments
  result <- slurp_ass(file.path("intermediates", "bigdump"))
  
  # join back onto these whether or not they were Train or Test and add a "Correct" column
  # and also a number of loci column.  And return that data frame.
  result %>%
    left_join(Split, ., by = c("INDV" = "ID")) %>%
    mutate(Correct = (From == To),
           NumLoci = nL)
}
```

## Finally, let's do some experiments

### Selecting loci on the basis of vcftools-calculated global FST

We do the experiment with the same numbers of loci as done in the original paper.
```{r}
# number of SNPs
LocNums <- c(500, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 10156)

# do them all...
ResList <- lapply(LocNums, function(x) thl(x, Split, train_FST))

# then make a big tidy data frame of it:
ResDF <- bind_rows(ResList)

# compute the proportion correct from each population under each scenario of
# NumLoci and Train/Test
SumDF <- ResDF %>%
  group_by(NumLoci, From, Pool) %>%
  summarize(NumCorrect = sum(Correct),
            Ppn_Correct = NumCorrect / n())
```
Here is what that result data set looks like:
```{r}
SumDF
```
Note that doing THL correctly requires that one focus only on the Test individuals to calculate the proportion of
correct assignment.  If you use only the training individuals or if you use both the training and the test individuals
then that will give you upwardly biased predictions of the power for assignment.  It will actually be worth seeing what the
result looks like if you use both the Training and the Test individuals to assess the proportion of correct assignments.
We can do that like this by labeling those individuals as "Both," summarizing, then appending to SumDF.
```{r}
tmpDF <- ResDF
tmpDF$Pool <- "Both"
NewSumDF <- tmpDF %>%
  group_by(NumLoci, From, Pool) %>%
  summarize(NumCorrect = sum(Correct),
            Ppn_Correct = NumCorrect / n()) %>%
  bind_rows(SumDF, .) %>%
  ungroup
```
It might be instructive to see what that data frame looks like:
```{r}
NewSumDF
```
And now we can can plot boxplots from those results. X-axis is number of loci 
(as factor), and Y-axis is proportion of correct
self-assignment in each sampling location.  In other words, each boxplot 
summarizes the results over all the
different sampling locations.

The different colors denote what happens when you use different sets of individuals as the
"Test" set, i.e. either the Holdout individuals (correct) or the Training individuals
(incorrect and subject to high grading bias) or Both the Training and the Holdout individuals
(also incorrect and subject to high grading bias).


```{r boxplots, fig.width=10, fig.height=7}
ggplot(NewSumDF, aes(x = factor(NumLoci), y = Ppn_Correct, fill = Pool)) +
  geom_boxplot()
```

So, when we assess these markers using THL with selection based on global Fst as computed by
`vcftools` we find that there isn't that much power for identifying different sampling locations, and
the pattern observed by Benestan et al. looks a lot like what we see with high-grading bias.
There are a number of possibilities:

1. Benestan et al. are doing locus selection in a different manner that is better than using global
  Fst, or they have found a better way of assessing power than THL that is still robust against
  high grading bias.  This would be very interesting and fun to follow up on.
1. We have made a mistake in our calculations.  (Always possible, which is why Eric tries to package this
  sort of stuff up in a reproducible package that shows explicitly what we have done, so any errors
  can be found!)
1. Benestan et al. have an error in their power assessment procedure that gives overly optimistic
  results.  If so, this would suggest that easy tools for accurately assessing assignment power correctly 
  (especially from large RAD data sets) are needed.  Perhaps we could generalize the R code used
  here into an R-package.
  

## Following up on Benestan's proposed erratum

Laura got back to us with a proposed erratum.  We will check up on some of her numbers here.  

### Population assignment the way they did it

Apparently, Laura accidentally used all the individuals as a training set and then used a random half of
those individuals as the holdout/test set.  So, let's see if we can reproduce her results by doing that.

Our variable `FST` holds the ranking of the loci by FST when using everyone as the training data.  So, we 
can just substitute that into our function, using the same individuals as before as the test data (which
were not properly held out!).  Note that we have to sort the FST results to use them
```{r bogusTrain}
# arrange FST from all individuals
bogus_trainFST <- FST %>%
  arrange(desc(WEIR_AND_COCKERHAM_FST))
```
Check out the top loci in this...Interestingly the loci with the highest Fst's here don't seem to intersect
with those from `trainFST`...
```{r}
bogus_trainFST
```

Now, go ahead and do the runs
```{r like_Bene}
# do them all...
ResList_bene <- lapply(LocNums, function(x) thl(x, Split, bogus_trainFST))

# then make a big tidy data frame of it:
ResDF_bene <- bind_rows(ResList_bene)

# compute the proportion correct from each population under each scenario of
# NumLoci and Train/Test
SumDF_bene <- ResDF_bene %>%
  group_by(NumLoci, From, Pool) %>%
  summarize(NumCorrect = sum(Correct),
            Ppn_Correct = NumCorrect / n())
```
And after that we plot it:
```{r}
ggplot(SumDF_bene, aes(x = factor(NumLoci), y = Ppn_Correct, fill = Pool)) +
  geom_boxplot()
```
OK, that is sort of what we might expect it to look like, and it looks a lot like the result that
Benestan et al. got. 

However, when Laura did it over again recently (in a more correct fashion),
she reported correct assignment to population of 
39.4%, which is almost twice what we see here.  So, I suspect that she still has an error in what she
did.

### Assignment to regional groups using the population assignments
The erratum that Laura sent me claims that the assignment to regional groups does not suffer from
a very noticeable high grading bias and the true assignment success to north and south should be 
correct, about 94.5\% of the time.  

I want to do a quick check on that just using the population-level assignments, and then we will
toss the individuals into separate "North" and "South" populations, which is how I think that 
Laura did it.

So, let's get a data frame with the regional groups and then define the regions in ResDF
```{r}
Pop_n_reg <- readRDS("data/RegionsAndPops.rds")
RegionalDF <- left_join(ResDF, Pop_n_reg, by = c("From" = "Pop")) %>%
  rename(FromRegion = Region) %>%
  left_join(., Pop_n_reg, by = c("To" = "Pop")) %>%
  rename(ToRegion = Region) %>%
  mutate(RegionCorrect = FromRegion == ToRegion)

# and summarize too
RegionalSummary <- RegionalDF %>%
  group_by(NumLoci, From, Pool) %>%
  summarize(NumCorrect = sum(RegionCorrect),
            Ppn_Correct = NumCorrect / n())
```
Then we can plot that:
```{r}
ggplot(RegionalSummary, aes(x = factor(NumLoci), y = Ppn_Correct, fill = Pool)) +
  geom_boxplot()
```
So, if you break everything into separate populations and then group them into
"lobster regions", you are doing pretty well with all the markers, but not as well with
3000 markers.  Pretty much just what you would expect.

But, then, one might do better by pooling all the regional samples so that the sample
sizes are large for North and South.



We have a problem, here, it turns out, in that the Pop identifiers in the paper don't full correspond
to what we find in the data set on Dryad.  Let's check that out.
```{r}
# here are the pops from the dryad file IDs:
dryad_pops <- unique(ResDF$SampSite)

# here are the pops listed in the paper in the table with
# the North and South designations
paper_pops <- Pop_n_reg$Pop

# here are the ones that are common
popcommon <- intersect(dryad_pops, paper_pops)

# and here are the ones that aren't common to each set
union(dryad_pops, paper_pops) %>%
  setdiff(., popcommon)
```

OK, so here is what we will do.  It is sort of a hack, and won't be totally legit, but will
use the computation we did previously.  We just toss out any individuals for whom the From or 
the To columns are not in `popcommon`.  This means tossing about 900 indivs from ResDF:
```{r}

RegDF <- ResDF %>%
  filter(To %in% popcommon, From %in% popcommon) %>%
  left_join(., Pop_n_reg, by = c("From" = "Pop")) %>%
  rename(FromRegion = Region) %>%
  left_join(., Pop_n_reg, by = c("To" = "Pop")) %>%
  rename(ToRegion = Region) %>%
  left_join(., Pop_n_reg, by = c("From" = "Pop")) %>%
  mutate(RegionCorrect = FromRegion == ToRegion)
```
Then summarize the number/ppn correct according to whether they are from South or North.
```{r}
SumDF_region <- RegDF %>%
  group_by(NumLoci, FromRegion, Pool) %>%
  summarize(RegionNumCorrect = sum(RegionCorrect),
            RegionPpn_Correct = RegionNumCorrect / n())
```
Then, go ahead an plot those up...
```{r}
ggplot(SumDF_region, aes(x = NumLoci, y = RegionPpn_Correct, colour = Pool)) +
  geom_line() +
  geom_point() +
  facet_wrap(~ FromRegion, ncol = 2)
```
This shows us that if we do that population assignment by population and then
assign the individual to North or South according to which population it is 
assigned to, then you get about 77% correct assignment of North lobsters and 
about 94% correct assignment of South lobsters.  So, one could potentially do better when merging all the North and South populations into two big populations.  We shall investigate that now...

### Assignment to regional groups using regional groups as populations
The way we have hacked this together, it is going to be easiest to change the original VCF file so that
we can still use all the same functions.  We will just prepend "South" or "North" to the ID of each
individuals, which will give us "Populations" of "Sou" and "Nor".  Once again, we have to toss out IDs that
don't correspond to the IDs given in the paper, but that is probably OK for now....
```{r}
vcf_lines <- readLines("intermediates/10156-586-IDs-corrected.vcf")
header_idx <- which(str_detect(vcf_lines, "^#CHROM"))  # line has all the names
header_elements <- vcf_lines[header_idx] %>%
  str_split(., "\t") %>%
  "[["(.,1)

# now we want to prepend a North or a South to each if appropriate:
ids_df <- data.frame(ID = header_elements[-(1:9)], stringsAsFactors = FALSE) %>%
  tbl_df %>%
  mutate(Pop = str_sub(ID, 1, 3)) %>% 
  left_join(Pop_n_reg) %>%
  mutate(NewID = paste(Region, ID, sep = "_"))


# we get a file of individual names that we want and print it out
ids_df %>%
  filter(str_detect(NewID, "North") | str_detect(NewID, "South")) %>%
  arrange(NewID) %>%
  select(NewID) %>% 
  unlist %>%
  unname %>%
  cat(., sep = "\n", file = "intermediates/north_south_names.txt") 

# now we make our new header line and write that out into a new VCF file
new_header_line <- c(header_elements[1:9], ids_df$NewID) %>%
  paste(., collapse = "\t")

vcf_lines[header_idx] <- new_header_line

cat(vcf_lines, file = "intermediates/north_south_renamed.vcf", sep = "\n")

# and now we keep only the ones that we know are in North or South...
system("source ~/.bashrc; vcftools --vcf intermediates/north_south_renamed.vcf --keep intermediates/north_south_names.txt --out intermediates/final_north_south --recode")
```

OK, with that done, let's just run gsi_sim using all the markers as a first pass / check.
```{r}
vcf2gsi_sim("intermediates/final_north_south.recode.vcf", outf = "intermediates/north_south_baseline.txt")

system("source ~/.bashrc; /Users/eriq/Documents/git-repos/gsi_sim/gsisim -b intermediates/north_south_baseline.txt --self-assign > intermediates/north_south_all_out.txt")

allLoci <- slurp_ass("intermediates/north_south_all_out.txt")
```

Now we can see how those came out:
```{r}
allLoci %>%
  group_by(From, To) %>%
  tally()
```
Which tells us that lobsters from the North get assigned correctly about 90% of the time, and lobsters from
the South get assigned correctly about 95% of the time, using all of the loci.  

So, this gives us a maximum power that we should expect.  It is unwise to think that you can
do any better (on average) with a smaller, selected subset of loci.  So, I think this is sufficient
to say that the Benestan et al markers can assign lobsters to North or South pretty well.  I don't find 94.5% correct assignment of both North and South lobsters, as Benestan et al. claim, but it's not far off.


when both north 